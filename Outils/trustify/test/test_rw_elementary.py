"""
Testing loading of various **elementary pieces** of TRUST datasets into the datamodel generated by trustpy.
"""

import os
import unittest

from test.reference_data import *
import trustify.base as base
import trustify.misc_utilities as mutil
from trustify.misc_utilities import ClassFactory, logger
from trustify.trust_parser import TRUSTParser, TRUSTStream, TRUSTEndOfStreamException

########################################################################################
class TestCase(unittest.TestCase, mutil.UnitUtils):
    """
    Testing loading of various dataset examples into the data model generated by trustpy.
    Also test that the model can reproduce the initial dataset once it has been parsed.
    """

    _test_dir = os.path.abspath(os.path.dirname(__file__))
    _models = []

    def _import_and_gen_stream(self, simple_str, simplify):
        """ From a string, generates the corresponding token stream that can be passed to ReadFromTokens() metods """
        # Generate if needed
        self.generate_python_and_import("simple")
        self.mod = self._TRUG["simple"]

        # Parse the TRUST data set provided in arg
        if simplify:
            data_ex = mutil.simplify_successive_blanks(simple_str)
        else:
            data_ex = simple_str
        tp = TRUSTParser()
        tp.tokenize(data_ex)
        stream = TRUSTStream(tp)
        logger.debug("Token list (original)    : %s" % stream.tok)
        logger.debug("Token list (low stripped): %s" % stream.tokLow)
        logger.debug("Token list has %d items" % len(stream))
        return stream

    def builtin_test(self, builtin_cls , simple_str, simplify=True):
        """ Generic test method taking a builtin Python type, a string representing an extract of a data set
        and returning the corresponding stream, the value, and the parser object.
        """
        stream = self._import_and_gen_stream(simple_str, simplify)
        pars_cls = base.Builtin_Parser.DispatchFromBuiltin(builtin_cls, stream)
        val, pars = pars_cls.ReadFromTokensBuiltin(stream)
        return stream, val, pars

    def string_test(self, cls_nam , simple_str, simplify=True):
        """ Generic test method taking the string representing the arguments of a class and parse it. """
        stream = self._import_and_gen_stream(simple_str, simplify)
        ze_cls = ClassFactory.GetClassFromName(cls_nam)
        return stream, ze_cls.ReadFromTokens(stream)

    def generic_test(self, data_ex_orig, simplify=True):
        """ Generic test method taking a (piece of) dataset and testing it.
        This is a (much) simpler version of base.DataSet_Parser.ReadFromTokens()
        It returns the parser stream, and the object created.
        """
        stream = self._import_and_gen_stream(simple_str, simplify)

        data_list = []  # A list representing the object found in the TRUST data file

        # Mimick (in a minimal fashion) what is done in DataSet.ReadFromTokens():
        cls_nam = stream.probeNextLow()
        ze_cls = ClassFactory.GetClassFromName(cls_nam)

        val = ze_cls.ReadFromTokens(stream)
        return stream, val

    #########################################################

    def test_parser(self):
        # Test parsing quotes
        data_ex = """ system "rm -rf */toto.lml.gz" one two"""
        tp = TRUSTParser()
        tp.tokenize(data_ex)
        stream = TRUSTStream(tp)
        self.assertEqual(stream.tokLow, ['', 'system', '"rm-rf*/toto.lml.gz"', 'one', 'two'])
        # Test EOF functionnality
        data_ex = """ # with comment #   toto      """
        stream, _, _ = self.builtin_test(str, data_ex, simplify=False)
        self.assertTrue(stream.eof())

    def test_simple_str(self):
        """ Test parsing simple string """
        data_ex = """
          # with many comments
            before
          #
          toto"""
        stream, val, pars = self.builtin_test(str, data_ex, simplify=False)
        expec = "toto"
        self.assertEqual(expec, val)
        self.assertTrue(stream.eof())
        # Test writing out
        res = ''.join(pars.toDatasetTokens())
        self.assertTrue(mutil.check_str_equality(res, data_ex).ok)
        # Test inner braces in 'Chaine_Parser' (what makes 'bloc_lecture' work!)
        # For this case, everything is kept in the resulting value, because we notably want to
        # remain case-sensitive.
        data_ex = """
          # with many comments
            before
          #
          { ta tu { toto } bouh }"""
        stream, val, pars = self.builtin_test(str, data_ex, simplify=False)
        expec = data_ex  # see comment above
        self.assertEqual(expec, val)
        self.assertTrue(stream.eof())
        # Test writing out
        res = ''.join(pars.toDatasetTokens())
        self.assertTrue(mutil.check_str_equality(res, data_ex).ok)
        # Misformatted '{' should fail:
        data_ex = "} toto }"
        # self.builtin_test(str, data_ex, simplify=False)
        self.assertRaises(ValueError, self.builtin_test, str, data_ex)
        data_ex = "   {toto }"
        # self.builtin_test(str, data_ex, simplify=False)
        self.assertRaises(ValueError, self.builtin_test, str, data_ex)

    def test_float_lst(self):
        """ Test parsing simple float list """
        mod = self._TRUG[0]

        # Simple float first
        data_ex = """# comment #
    35.6"""
        stream, inst = self.string_test("base_float", data_ex, simplify=False)
        BF = self.mod.Base_float
        expec = BF(35.6)
        self.assertTrue(expec == inst)
        self.assertTrue(stream.eof())
        # Test writing out:
        res = ''.join(inst.toDatasetTokens())
        self.assertTrue(mutil.check_str_equality(res, data_ex).ok)

        # List of floats now:
        data_ex = "3 48.5 89.2 18"
        stream, inst = self.string_test("list_float", data_ex)
        LT, BF = self.mod.List_float, self.mod.Base_float
        expec = LT()
        expec.extend([BF(48.5), BF(89.2), BF(18.0)])
        self.assertTrue(expec == inst)
        self.assertTrue(stream.eof())

        # Test writing out:
        res = ''.join(inst.toDatasetTokens())
        self.assertTrue(mutil.check_str_equality(res, data_ex).ok)

        # Changing value on the model side should change output, and not reproduce initial tokens!!
        inst[1] = BF(39.3)
        new_s = "3 48.5 39.3 18"
        res = ''.join(inst.toDatasetTokens())
        self.assertEqual(res, new_s)
        inst.pop()
        new_s = " 2 48.5 39.3"  # yes a space to start with ...
        res = ''.join(inst.toDatasetTokens())
        self.assertEqual(res, new_s)

        # Same thing stressing parser:
        data_ex = """3   48.5
         89.2 # comment inside #  18"""
        stream, inst = self.string_test("list_float", data_ex, simplify=False)  # warning: no simplification here
        LT, BF = self.mod.List_float, self.mod.Base_float
        expec = LT()
        expec.extend([BF(48.5), BF(89.2), BF(18.0)])

        self.assertTrue(expec == inst)
        self.assertTrue(stream.eof())
        s = ''.join(inst.toDatasetTokens())
        self.assertEqual(s, data_ex)

        # Changing value on the model side should change output, and not reproduce initial tokens!!
        inst[0] = BF(39.3)
        new_s = """3 39.3
         89.2 # comment inside #  18"""
        res = ''.join(inst.toDatasetTokens())
        self.assertEqual(res, new_s)
        inst.pop()
        new_s = """ 2 39.3
         89.2""" # yes a space to start with ...
        res = ''.join(inst.toDatasetTokens())
        self.assertEqual(res, new_s)

        # Ill formed lists
        data_ex = "3 48.5 89.2"
        #offset, inst = self.string_test("list", data_ex)
        self.assertRaises(TRUSTEndOfStreamException, self.string_test, "list_float", data_ex)
        data_ex = "3 48.5 89.2 sfsf"
        #offset, inst = self.string_test("list", data_ex)
        self.assertRaises(ValueError, self.string_test, "list_float", data_ex)

    def test_curly_br(self):
        """ Test parsing and loading of a minimal TRUST dataset using curly braces """
        data_ex = """
        # Some stupid test #
        read_MED_bidon
          {
             mesh ze_mesh_name
             file a/complicated/path/to.med
             exclude_groups 2 toto titi
             convertAllToPoly
          }"""
        for simplify in [True, False]:
            stream, res = self.generic_test(data_ex, simplify=simplify)
            exp = buildCurlyExpec(self._TRUG[0])
            self.assertTrue(exp == res)
            self.assertTrue(stream.eof())
            if not simplify:
                # Testing writing out
                s = ''.join(res.toDatasetTokens())
                self.assertTrue(mutil.check_str_equality(s, data_ex).ok)

        # Modifying data should change output!!
        res.convertalltopoly = False
        res.file = "new/file.med"
        s = ''.join(res.toDatasetTokens())
        new_s = """
        # Some stupid test #
        read_MED_bidon
          {
             mesh ze_mesh_name
             file new/file.med
             exclude_groups 2 toto titi
          }"""
        self.assertTrue(mutil.check_str_equality(s, new_s).ok)

        # Ill-formed dataset - missing brace
        data_ex = """
        # Some stupid test #
        read_MED_bidon

             mesh ze_mesh_name
             file a/complicated/path/to.med
             exclude_groups 2 toto titi
             convertAllToPoly
          }"""
        # self.generic_test(data_ex)
        self.assertRaises(ValueError, self.generic_test, data_ex)
        # Ill-formed dataset - missing brace
        data_ex = """
        # Some stupid test #
        read_MED_bidon
          {
             mesh ze_mesh_name
             file a/complicated/path/to.med
             exclude_groups 2 toto titi
             convertAllToPoly"""
        self.assertRaises(TRUSTEndOfStreamException, self.generic_test, data_ex)

    def test_parser_stress(self):
        """ Basic test - stressing parser """
        data_ex = """read_MED_bidon { mesh ze_mesh_name file a/complicated/path/to.med exclude_groups 2 toto titi convertAllToPoly }"""
        stream, res = self.generic_test(data_ex, simplify=False)
        exp = buildCurlyExpec(mod)
        self.assertTrue(exp.equal(res))
        self.assertTrue(stream.eof())
        # Test writing out:
        s = ''.join(res.toDatasetTokens())
        self.assertTrue(mutil.check_str_equality(s, data_ex).ok)

        data_ex += " toto"  # should still parse, 'toto' being the next keyword in the stream
        stream, res = self.generic_test(data_ex, simplify=False)
        self.assertTrue(exp.equal(res))
        self.assertFalse(stream.eof())  # but not end of stream

    def test_opt_attr(self):
        """ Test attribute optionality. Missing required attribute should fail the parse. """
        data_ex = """
        # Invalid data with missing required attribute (file) #
        read_MED_bidon
          {
             mesh ze_mesh_name
             # file a/complicated/path/to.med #
             exclude_groups 2 toto titi
             convertAllToPoly
          }
        """
        # Should fail since mandatory attribue 'file' is missing:
        self.assertRaises(ValueError, self.generic_test, data_ex)

        # Keyword with all optionals should accept no attributes at all:
        data_ex = """coucou { }"""
        stream, res = self.generic_test(data_ex)
        MB = self.mod.coucou
        expec = MB()
        self.assertTrue(expec.equal(res))
        self.assertTrue(stream.eof())
        # Test writing out:
        s = ''.join(res.toDatasetTokens())
        self.assertTrue(mutil.check_str_equality(s, data_ex).ok)

    def test_synonyms(self):
        """ Test synonyms """
        data_ex = """
        # Some stupid test with syno #
        read_MED_bidon
          {
             maillage ze_mesh_name
             fichier a/complicated/path/to.med
             exclude_groups 2 toto titi
             convertAllToPoly
          }"""
        for simplify in [True, False]:
            stream, res = self.generic_test(data_ex, simplify=simplify)
            exp = buildCurlyExpec(mod)
            self.assertTrue(exp.equal(res))
            self.assertTrue(stream.eof())
            if not simplify:
                # Test writing out:
                s = ''.join(res.toDatasetTokens())
                self.assertTrue(mutil.check_str_equality(s, data_ex).ok)

    def test_no_curly_br(self):
        """ Testing keywords with no curly braces """
        # Standard case
        data_ex = """uniform_field 3 34.6 12.8 90.9"""
        stream, res = self.generic_test(data_ex)
        UF, LT, BF = self.mod.uniform_field, self.mod.list, self.mod.BaseFloattant
        # Build expected value
        exp, l = UF(), LT()
        l.extend([BF(34.6), BF(12.8), BF(90.9)])
        exp.val = l
        self.assertTrue(res.equal(exp))
        self.assertTrue(stream.eof())
        # Test writing out:
        s = ''.join(res.toDatasetTokens())
        self.assertTrue(mutil.check_str_equality(s, data_ex).ok)

        # The below should parse - 'toto' can be considered the next keyword in the stream
        data_ex2 = data_ex + " toto "
        stream, res = self.generic_test(data_ex2)
        self.assertTrue(res.equal(exp))
        #   here we re not at EOF, since 'toto' is there
        self.assertFalse(stream.eof())
        # With an optional flag and more spaces in between!
        data_ex = """
        # Example no curly brace with optional #
        uniform_field   flag_bidon  3   34.6  12.8 90.9
           flag_bidon2  2 15   29"""
        for simplify in [True, False]:
            stream, res = self.generic_test(data_ex, simplify=simplify)
            exp, l, l2 = UF(), LT(), LT()
            l.extend([BF(34.6), BF(12.8), BF(90.9)])
            l2.extend([BF(15), BF(29)])
            exp.val, exp.val2 = l, l2
            exp.flag_bidon, exp.flag_bidon2 = "flag_bidon", "flag_bidon2"
            self.assertTrue(res.equal(exp))
            self.assertTrue(stream.eof())
            if not simplify:
                # Test writing out:
                s = ''.join(res.toDatasetTokens())
                self.assertTrue(mutil.check_str_equality(s, data_ex).ok)

        # Same story with next keyword:
        data_ex2 = data_ex + " toto "
        stream, res = self.generic_test(data_ex2)
        self.assertTrue(res.equal(exp))
        self.assertFalse(stream.eof())

        # Ill-formed dataset (missing attribute):
        data_ex = """
        # Ill-formed #
        uniform_field flag_bidon
        """
        # self.generic_test(data_ex)
        self.assertRaises(TRUSTEndOfStreamException, self.generic_test, data_ex)
        # Ill-formed dataset (missing values)
        data_ex = """
        # Ill-formed #
        uniform_field 3 34.6 12.8
        """
        # self.generic_test(data_ex)
        self.assertRaises(TRUSTEndOfStreamException, self.generic_test, data_ex)

    def test_complex_attr(self):
        """ Testing complex attributes (with a prescribed type) """
        data_ex = """
          coucou {
            attr_bidon champ_uniforme 2 0 9.8
          }"""
        for simplify in [True, False]:
            stream, res = self.generic_test(data_ex, simplify=simplify)
            MB = self.mod.coucou
            UF, LT, BF = self.mod.uniform_field, self.mod.list, self.mod.BaseFloattant
            # Build expected value
            exp, uf, l = MB(), UF(), LT()
            l.extend([BF(0), BF(9.8)])
            uf.val = l
            exp.attr_bidon = uf

            self.assertTrue(res.equal(exp))
            self.assertTrue(stream.eof())
            if not simplify:
                # Test writing out:
                s = ''.join(res.toDatasetTokens())
                self.assertTrue(mutil.check_str_equality(s, data_ex).ok)

    def test_adding_attr(self):
        """ Testing adding an attribute to a keyword and checking output ok """
        data_ex = """
        # Some stupid test with syno #
        read_MED_bidon
          {
             maillage ze_mesh_name
             fichier a/complicated/path/to.med
             exclude_groups 2 toto titi
             convertAllToPoly
          }"""

        stream, res = self.generic_test(data_ex, simplify=False)
        exp = buildCurlyExpec(mod)
        self.assertTrue(exp.equal(res))
        self.assertTrue(stream.eof())
        # Adding a (valid) attribute
        res.no_family_names_from_group_names = True
        data_expected = """
        # Some stupid test with syno #
        read_MED_bidon
          {
             maillage ze_mesh_name
             fichier a/complicated/path/to.med
             exclude_groups 2 toto titi
             convertAllToPoly
    no_family_names_from_group_names
          }"""  # Yes I know this is poorly indented ...
        # Test writing out:
        s = ''.join(res.toDatasetTokens())
        self.assertTrue(mutil.check_str_equality(s, data_expected).ok)

    def test_inheritance(self):
        """ Testing inheritance - gravite expects a 'field_base' of which 'champ_uniform' is a child
        """
        data_ex = """
          coucou {
            gravite champ_uniforme 2 0 9.8
          }"""
        for simplify in [True, False]:
            stream, res = self.generic_test(data_ex, simplify=simplify)
            MB = self.mod.coucou
            UF, LT, BF = self.mod.uniform_field, self.mod.list, self.mod.BaseFloattant
            # Build expected value
            exp, uf, l = MB(), UF(), LT()
            l.extend([BF(0), BF(9.8)])
            uf.val = l
            exp.gravite = uf
            # Test
            self.assertTrue(res.equal(exp))
            self.assertTrue(stream.eof())
            if not simplify:
                # Test writing out:
                s = ''.join(res.toDatasetTokens())
                self.assertTrue(mutil.check_str_equality(s, data_ex).ok)

        # Changing inherited attribute should change output:
        FB = self.mod.field_base
        res.gravite = FB()
        s = ''.join(res.toDatasetTokens())
        new_s = """
          coucou {
            gravite field_base
          }"""
        self.assertTrue(mutil.check_str_equality(s, new_s).ok)

        # Wrong inheritance should raise:
        data_ex = """
          coucou {
            gravite coucou { }
          }
        """
        # offset, res = self.generic_test(data_ex)
        self.assertRaises(Exception, self.generic_test, data_ex)

    def test_forward_decl(self):
        """ Testing forward declaration and 'read' keyword.
        This uses the main loop from DataSet. """
        data_ex = """
        lire_med_bidon   rmed    # bidon because not an interpret #
        coucou cb

        Read  rmed
          {
             mesh ze_mesh_name
             file a/complicated/path/to.med
          }

        read    cb {   }"""
        # Generate if needed
        self.generate_python_and_import_simple()
        tds_cls = self.getClassFromName("DataSet")
        # Parse the TRUST data set provided in arg
        tp = TRUSTParser()

        for simplify in [True, False]:
            if simplify:
                data_ex_mod = mutil.simplify_successive_blanks(data_ex)
            else:
                data_ex_mod = data_ex
            tp.tokenize(data_ex_mod)
            stream = TRUSTStream(tp)
            logger.debug("Token list (original)           : %s" % stream.tok)
            logger.debug("Token list (lower case stripped): %s" % stream.tokLow)
            logger.debug("Token list has %d items" % len(stream))
            res = tds_cls.ReadFromTokens(stream)
            self.assertEqual(len(res), 4)
            self.assertTrue(stream.eof())
            exp0, exp1, exp2, exp3 = buildForwardExpec(mod)
            self.assertTrue(exp0.equal(res[0])) # Forward decl
            self.assertTrue(exp1.equal(res[1])) # Coucou cb
            self.assertTrue(exp2.equal(res[2])) # read rmed
            self.assertTrue(exp3.equal(res[3])) # read cb
            if not simplify:
                # Test writing out:
                s = ''.join(res.toDatasetTokens())
                self.assertTrue(mutil.check_str_equality(s, data_ex).ok)

    def test_forward_decl2(self):
        """ Forward declaration test.
        This uses the main loop from DataSet. """
        # Valid dataset
        data_ex = """champ_uniforme gravite
                     read gravite 2 0.0 9.8"""
        self.generate_python_and_import_simple()
        tds_cls = self.getClassFromName("DataSet")
        tp = TRUSTParser()
        tp.tokenize(data_ex)
        stream = TRUSTStream(tp)
        res = tds_cls.ReadFromTokens(stream)
        self.assertEqual(len(res), 2)
        self.assertTrue(stream.eof())
        UF, D, LF = self.mod.uniform_field, self.mod.Declaration, self.mod.ListOfFloat
        decl = D()
        decl.identifier, decl.cls_nam = "gravite", "champ_uniforme"
        f, l = UF(), LF([0,9.8])
        f.val = l
        self.assertTrue(res[0].equal(decl))
        self.assertTrue(res[1].equal(f))
        # Test writing out:
        s = ''.join(res.toDatasetTokens())
        self.assertTrue(mutil.check_str_equality(s, data_ex).ok)

        # Invalid datasets
        #    Misformatted fwd decl:
        data_ex = """champ_uniforme 35
                     coucou { }"""
        tp.tokenize(data_ex)
        stream = TRUSTStream(tp)
        # res = tds_cls.ReadFromTokens(stream)
        self.assertRaises(ValueError, tds_cls.ReadFromTokens, stream)
        #    Misformatted - trying to make a forward declaration with an interprete:
        data_ex = """champ_uniforme gravite
                     lire_med forward"""
        tp.tokenize(data_ex)
        stream = TRUSTStream(tp)
        # res = tds_cls.ReadFromTokens(stream)
        self.assertRaises(ValueError, tds_cls.ReadFromTokens, stream)

    def test_complete_dataset(self):
        """ Complete dataset with foward declarations etc... """
        data_ex = """
        # Some stupid test #
        champ_uniforme gravite
        nom coucou
        read gravite 2 28 32   # Keyword with no brace #
        read coucou toto
        lire_MED
          {
             mesh ze_mesh_name
             file a/complicated/path/to.med
             exclude_groups 2 toto titi
             convertAllToPoly
          }"""

        # Generate if needed
        self.generate_python_and_import_simple()
        tds_cls = self.getClassFromName("DataSet")
        # Parse the TRUST data set provided in arg
        tp = TRUSTParser()

        for simplify in [True, False]:
            if simplify:
                data_ex_mod = mutil.simplify_successive_blanks(data_ex)
            else:
                data_ex_mod = data_ex
            tp.tokenize(data_ex_mod)
            stream = TRUSTStream(tp)
            logger.debug("Token list: %s" % stream.tokLow)
            logger.debug("Token list has %d items" % len(stream))
            res = tds_cls.ReadFromTokens(stream)
            self.assertEqual(len(res), 5)
            self.assertTrue(stream.eof())

            exp = buildMinimalExpec(mod)
            for i in range(5):
                self.assertTrue(exp[i].equal(res[i]))
            if not simplify:
                # Test writing out:
                s = ''.join(res.toDatasetTokens())
                self.assertTrue(mutil.check_str_equality(s, data_ex).ok)

if __name__ == '__main__':
    verbose = True  # verbose if in main
    mutil._log_level = 4
    unittest.main()
