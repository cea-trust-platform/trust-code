{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b5fbf83",
   "metadata": {},
   "source": [
    "# Hello World example - trustify Python package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b37db1",
   "metadata": {},
   "source": [
    "This is a simple hello world notebook illustrating what can be done with trustify.\n",
    "\n",
    "The TRAD2 has already been generated and is provided in the same folder as this notebook\n",
    "(if you care, it was generated with an intermediate TRUST version somewhere between 1.9.2 \n",
    "and 1.9.3).\n",
    "\n",
    "The example detailed here:\n",
    "- generates the Python data model from this TRAD2 file -> Python module 'hello_gen_pyd.py' and 'hello_gen_pars.py' are produced.\n",
    "- and then illustrates how an actual dataset (coherent with the TRAD2 provided) can be loaded, and manipulated. \n",
    "\n",
    "To run this notebook properly, you should ensure that the Python environment has been properly loaded\n",
    "with\n",
    "\n",
    "```\n",
    "    source $TRUST_ROOT/env_for_python.sh\n",
    "```\n",
    "\n",
    "**Note** : this dataset might not be valid anymore as TRUST versions evolve, but it is coherent \n",
    "with the TRAD2 file provided in this folder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be77cbbc",
   "metadata": {},
   "source": [
    "## Python data model generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15ba778",
   "metadata": {},
   "source": [
    "This step can be skipped if you are working with a stable TRUST version and are not interested in modifying the TRUST grammar (i.e. you are not changing any syntax of a keyword, or not adding a new keyword, a new attribute for a keyword, etc.)\n",
    "\n",
    "Here we generate the Python data model from the TRAD2 file. This produces two Python module (hello_gen_pyd.py and hello_gen_pars.py) which encodes all the grammar of the TRUST keywords, i.e. what parameter they take, with what type, etc. and how they should be parsed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c23de1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import trustify.trad2_pydantic as t2p\n",
    "\n",
    "trad2 = \"TRAD2_example\"\n",
    "trad2_nfo = \"TRAD2_example.nfo\"\n",
    "pydantic_generated_file = \"hello_gen_pyd.py\"\n",
    "parsing_generated_file = \"hello_gen_pars.py\"\n",
    "t2p.generate_pyd_and_pars(Path(trad2), Path(trad2_nfo), Path(pydantic_generated_file), Path(parsing_generated_file))\n",
    "print(\"Automatic generation OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19721bfe-1a80-4de6-9d46-74059b0847a4",
   "metadata": {},
   "source": [
    "You can take a look at the generated files. The first one will contain only the Pydantic schema, the second one, all the information related to parsing. Note that the parsing module automatically import the Pydantic one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e650e357",
   "metadata": {},
   "source": [
    "## Dataset parsing and manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b0fc42",
   "metadata": {},
   "source": [
    "We are now ready to parse and manipulate our first dataset!\n",
    "\n",
    "We import what was generated : it suffices to import the parsing part, since it automatically imports the Pydantic part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab812693",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hello_gen_pars as hg  # you can replace this with the official TRUST generated module if you didn't take previous step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5ea897",
   "metadata": {},
   "source": [
    "Now we invoke the parser to load a TRUST dataset. The parser splits the dataset (a .data file) to produce a stream of tokens (=a somewhat clever list of strings, if you want). This stream will be next passed to the data model constructor.\n",
    "\n",
    "The parser (and the associated stream it produces) deals with the comments and other formatting elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4054472",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trustify.trust_parser import TRUSTParser, TRUSTStream\n",
    "\n",
    "fNam = \"upwind_simplified.data\"\n",
    "with open(fNam) as f:\n",
    "    data_ex = f.read()\n",
    "\n",
    "tp = TRUSTParser()\n",
    "tp.tokenize(data_ex)\n",
    "stream = TRUSTStream(tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fbac78",
   "metadata": {},
   "source": [
    "Let's print the dataset for future reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6173a594",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dd265e",
   "metadata": {},
   "source": [
    "And finally we load this into the data model that we have generated above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c0064f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = hg.Dataset_Parser.ReadFromTokens(stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c6751c",
   "metadata": {},
   "source": [
    "Now **ds** contains our TRUST dataset as a Python object and we can finally play with it! We show several examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135bc0ca",
   "metadata": {},
   "source": [
    "### Example: reading/adding a time scheme attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3340076",
   "metadata": {},
   "source": [
    "What is the current final time in our dataset ? Note in the below how the Python attributes exactly corresponds to the name of the attribute in the TRUST syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a852455f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Named object in the dataset are retrieved using the get() method:\n",
    "ze_time_scheme = ds.get(\"sch\")\n",
    "\n",
    "# Then attributes can be read using the option name of the TRUST keyword, here 'tmax':\n",
    "t_mx = ze_time_scheme.tmax\n",
    "print(\"tmax is %g\" % t_mx )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af350d2",
   "metadata": {},
   "source": [
    "If we want to inspect the list of available attributes, we can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebffe702",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ze_time_scheme.model_fields.keys())  # model_fields is provided by pydantic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42d3466",
   "metadata": {},
   "source": [
    "Another (more complete) possibility is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3699eec1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint  # Useful Python pretty print\n",
    "pprint(ze_time_scheme.model_fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43924345",
   "metadata": {},
   "source": [
    "We can now set an extra parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a829ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ze_time_scheme.tinit = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab615da-7f6b-4f4f-8d39-442b24577f28",
   "metadata": {},
   "source": [
    "Notice how this fail if you try to assign the wrong type (here a string instead of a double):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f3343a-bb90-4d9d-a187-4417f20364cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ze_time_scheme.tinit = \"tutu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448818e5",
   "metadata": {},
   "source": [
    "### Example: reading the name of the first probe\n",
    "Same story with a more complex things: the name of the first probe ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559c9e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the problem named 'pb' in the dataset:\n",
    "ze_pb = ds.get(\"pb\")\n",
    "\n",
    "# Read the first probe in the postprocessing block:\n",
    "first_probe = ze_pb.post_processing.probes[0]\n",
    "print(first_probe.nom_sonde)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7e7aa4",
   "metadata": {},
   "source": [
    "... and then the x coordinate of the first point in the first probe: notice how some attributes might be painful and very dependent on how the TRUST grammar was built. In this case for example, the somewhat cryptic 'type' intermediate argument comes from the way the TRAD2 is defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb08686",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = first_probe.type.points[0].pos[0]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e409a9-9117-4d96-aee4-033201a07fec",
   "metadata": {},
   "source": [
    "## Validating the dataset\n",
    "\n",
    "On top of the automatic validation performed when you assign values, you can also explicitely request the model to validate itself by invoking:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39bd68b-daa8-4687-ace9-72d834d1d07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.self_validate()\n",
    "# Or we can also validate only part of the dataset:\n",
    "ze_time_scheme.self_validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78b0981-6c09-45a5-9cd6-9cd054eec014",
   "metadata": {},
   "source": [
    "This will fail (raising an exception) if any of the value contained is the model is not compliant with the type requested. This is particularly useful for complex types like lists, where pydantic can not perform the check when assigning the value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c7b86a",
   "metadata": {},
   "source": [
    "## Writing back the dataset\n",
    "The data can be modified ... and written back in a form of a new dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6229a951",
   "metadata": {},
   "source": [
    "Let's modify the y coordinate of the first probe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88db5bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_probe.type.points[0].pos[0] = -42.1  # as simple as that!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94eda89",
   "metadata": {},
   "source": [
    "We can also for example delete the second probe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7eabe66",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(ze_pb.post_processing.probes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdb427f",
   "metadata": {},
   "source": [
    "Now we produce a new stream of tokens corresponding to this modified instance. This stream of tokens can then be simply joined to find back a textual dataset with the modifed data. Notice how all the other comments and formatting is kept unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9183c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert back the data into a stream of tokens:\n",
    "newStream = ds.toDatasetTokens() \n",
    "# And write it out!\n",
    "s = ''.join(ds.toDatasetTokens())\n",
    "print(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
