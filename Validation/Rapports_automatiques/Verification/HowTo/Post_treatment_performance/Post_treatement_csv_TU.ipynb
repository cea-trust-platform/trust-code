{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eeb4f852",
   "metadata": {},
   "source": [
    "# Understand and use peformance log files in TRUST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925ded6c",
   "metadata": {},
   "source": [
    "## How performance are measured in TRUST\n",
    "\n",
    "In order to obtain statistics on the performance of a test case, TRUST uses counters. Each counter can be referred by a description/name and an ID. Those IDs are declared in the file stat_counters.h. They are global variables of TRUST. Some counters belong to a counter's family. Such families is used in practice to construct aggregated statistics which track similar types of operation. If a counter does not belong in a peculiar family, then Counter_family is set to (null).\n",
    "\n",
    "A unique object of the class Statistiques is then defined. It stores data associated with counters in an object called Stats_Internals. In the Statistiques class, are also provided functions for manipulating counters.\n",
    "\n",
    "During any numerical simulation, counters are started and then stop throughout the calculation by using respectively the functions begin_count(const Stat_Counter_Id& counter_id, bool track_comm) and end_count_(const int id, int quantity = 0, int count = 1). The end_count function also updates two variables, called count and quantity. The variable count refers by default to the number of time a counter has been called and is therfore by default incremented by one after using the function end_count. For some particular counter, the increment can be different. The variable quantity is a custom storage variable which differs from counter to counter. By default, it is set to 0. It is mostly used to store the amount of data exchanged between processors during a peculiar operation.\n",
    "\n",
    "At the end of the calculation, two files that store statistics of the performance are created. The first one is named CASE_NAME.TU. It is created by the function print_statistics_analyse(const char * message, int mode_append). Macro and aggregated statistics of the performance of the computed test case are available in it. \n",
    "The second file is called NOM_DU_CAS_csv.TU. This file contains untreated performance data from every counter aggregated over processors and statistics aggregated over each counter family. By default, only averaged statistics on all processor are printed. For accessing the detail per processor, add 'stat_per_proc_perf_log 1' in the data file. \n",
    "\n",
    "This form explains how to reconstruct some aggregated statistics of the CASE_NAME.TU file from this second file. \n",
    "\n",
    "For clarity, a table that details for each counter its name, ID, family, quantity increment and if it is a communication counter or not can be found at the end of this form. Another table that gives count increment for counters where it is not equal to 1 is also provided.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1836874",
   "metadata": {},
   "source": [
    "### Description of the csv file\n",
    " \n",
    "The performance log file CASE_NAME_csv.TU stores the statistics in a table for each counter on a specific test case. This table has the following columns: \n",
    "\n",
    "\"Overall_simulation_step\", \"Processor_Number\", \"Counter_family\", \"Counter_name\",  \"Counter_level\", \"Is_comm\", \"%_total_time\", \"time_(s)\", \"t_min\", \"t_max\", \"t_SD\", \"count\", \"c_min\", \"c_max\", \"c_SD\", \"time_per_step\", \"tps_min\", \"tps_max\", \"tps_SD\", \"Quantity\", \"q_min\", \"q_max\", \"q_SD\"\n",
    "\n",
    "Column delimiter is a tabulation. The first four columns create a unique key for a row.\n",
    "\n",
    "\"Overall_simulation_step\" can take the three following values: \n",
    "   - \"Statistiques d'initialisation du calcul\"\n",
    "   - \"Statistiques de resolution du probleme\"\n",
    "   - \"Statistiques de post resolution\". \n",
    "   \n",
    "This stands respectively for the three main steps of the calculation (initialisation, resolution and post processing). \n",
    "\n",
    "Column Is_comm enable to know if the counter is a communication counter or not. If it is equal to 1, then it is a communication counter. Otherwise, it is not.\n",
    "\n",
    "\"%_total_time\" gives the percentage of time used by a peculiar counter with respect to the total time used for the main step of calculation (initialisation, resolution and post processing).\n",
    "\n",
    "By default, averaged statistics on all processors are also available under Processor_Number == -1. For accessing the detail per processor, add 'stat_per_proc_perf_log 1' in the data file. Moreover, if count is equal to zero, then the counter was not called during the computation.\n",
    "\n",
    "Aggregated statistics on the counter family are also already computed and stored under the counter name : \"Aggregated over family\".\n",
    "\n",
    "SD stands for standard deviation. Min and max denote the minimum and maximum value over every processor of the accounted quantity. The \"time_per_step\" column stores the average time elapsed in a time step on the tracked operation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3cc734",
   "metadata": {},
   "source": [
    "## Exemple on the simple test case Obstacle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a8856b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trustutils import run\n",
    "\n",
    "run.TRUST_parameters(\"1.9.4_beta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7045f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.reset()\n",
    "case1 = run.addCase(\".\",\"Obstacle.data\",nbProcs=2)\n",
    "case1.partition()\n",
    "run.printCases()\n",
    "run.runCases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731a5cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.tablePerf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58571774",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(run.BUILD_DIRECTORY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405de649",
   "metadata": {},
   "source": [
    "First, we need to know the number of rows of comments there are before the table starts. Those rows always start with the character #."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a14bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_file = open('PAR_Obstacle_csv.TU',\"r\") \n",
    "\n",
    "lines=perf_file.readlines()\n",
    "\n",
    "nb_comment_lines=0\n",
    "\n",
    "while (lines[nb_comment_lines][0]=='#'):\n",
    "    nb_comment_lines +=1\n",
    "\n",
    "print(nb_comment_lines)  \n",
    "\n",
    "perf_file.closed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbe01f1",
   "metadata": {},
   "source": [
    "The file contains some white spaces, in order to make it readable by a human. They have to be removed so as to have a clean MultiIndex. To do so, three functions are created : strip, make_int and make_float. \n",
    "\n",
    "The column names are specified in the variable col_names. Here, by default, the same name as the first row of the table has been used, but you can customize it.\n",
    "\n",
    "Then, the file is open using pandas library and converted into a DataFrame. A quick user guide for pandas library can be found at : https://pandas.pydata.org/docs/user_guide/10min.html\n",
    "\n",
    "For opening the file, the function read.csv is used. The first argument is the path to the .csv file. Then, by using sep='\\t' we specify that the delimiter of the table is a tabulation. Header = 0 enables to change properly the name of the colums from the first row to the ones contain in the variable col_names. Argument index_col specifies the number of columns used as a key for a row (this will create a MultiIndex). Converters are used to discard useless white spaces in the table.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1b31e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as math\n",
    "\n",
    "def strip(text):\n",
    "    try:\n",
    "        return text.strip()\n",
    "    except AttributeError:\n",
    "        return text\n",
    "\n",
    "def make_int(text):\n",
    "    return int(text.strip('\" '))\n",
    "\n",
    "def make_float(text):\n",
    "    return float(text.strip('\" '))\n",
    "\n",
    "col_names=[\"Overall_simulation_step\", \"Processor_Number\", \"Counter_family\", \"Counter_name\",  \"Counter_level\", \"Is_comm\", \"%_total_time\", \"time_(s)\", \"t_min\", \"t_max\", \"t_SD\", \"count\", \"c_min\", \"c_max\", \"c_SD\", \"time_per_step\", \"tps_min\", \"tps_max\", \"tps_SD\", \"Quantity\", \"q_min\", \"q_max\", \"q_SD\"]\n",
    "\n",
    "M=pd.read_csv('PAR_Obstacle_csv.TU', sep='\\t', skiprows = nb_comment_lines, header=0, names=col_names, index_col=(0,1,2,3), converters= {\"Overall_simulation_step\" : strip, \"Processor_Number\" : make_int, \"Counter_family\" : strip, \"Counter_name\" : strip, \"Counter_level\" : make_int, \"Is_comm\" : make_int, \"%_total_time\" : make_float, \"time_(s)\" : make_float, \"t_min\" : make_float, \"t_max\" : make_float, \"t_SD\" : make_float, \"count\" : make_float, \"c_min\" : make_float, \"c_max\" : make_float, \"c_SD\" : make_float, \"time_per_step\" : make_float, \"tps_min\" : make_float, \"tps_max\" : make_float, \"tps_SD\" : make_float, \"Quantity\" : make_float, \"q_min\" : make_float, \"q_max\" : make_float, \"q_SD\" : make_float  })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76ce525",
   "metadata": {},
   "source": [
    "If you have a doubt in the MultiIndex, you can print it by using :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a0573c",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = M.index\n",
    "\n",
    "print(M.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a777d9",
   "metadata": {},
   "source": [
    "You can also have generic infromation about the DataFrame by using :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcefe16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "M.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6695fcb4",
   "metadata": {},
   "source": [
    "An advantage of the MultiIndex is that it is quite easy to make selection on partial index. First, let's create three sub DataFrames, one for each overall simulation step :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e30e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_init = M.loc[(\"Statistiques d'initialisation du calcul\")]\n",
    "M_reso = M.loc[(\"Statistiques de resolution du probleme\")]\n",
    "M_post = M.loc[(\"Statistiques de post resolution\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5226bf6",
   "metadata": {},
   "source": [
    "## How to reconstruct the agregated data of the .TU file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c3ad70",
   "metadata": {},
   "source": [
    "In the .Tu file, some usefull aggregated values are already computed. In the sequel, we show how to reconstruct them easily from the .csv file. First, let's print the file CASE_NAME.TU :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cc8236",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_perf_file = open('PAR_Obstacle.TU',\"r\") \n",
    "\n",
    "lines=aggregated_perf_file.readlines()\n",
    "\n",
    "for l in lines:\n",
    "    print(l)\n",
    "\n",
    "aggregated_perf_file.closed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89922d2",
   "metadata": {},
   "source": [
    "First, we need to know the number of proc used for the simulation. If statistics detailed by processor are printed, you can obtain it with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048d345c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nb_proc = np.max( idx.get_level_values(1) ) + 1    \n",
    "print(Nb_proc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709a7c95",
   "metadata": {},
   "source": [
    "Else, the information is also given in the second commented line of the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827c1596",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_file = open('PAR_Obstacle_csv.TU',\"r\") \n",
    "\n",
    "lines=perf_file.readlines()\n",
    "print(lines[1])\n",
    "\n",
    "for c in lines[1].split():\n",
    "    if c.isdigit():\n",
    "        Nb_proc=int(c)\n",
    "\n",
    "perf_file.closed\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e2c9ac",
   "metadata": {},
   "source": [
    "In the sequel, we give an example for treating statistics of the resolution step. Just change the name of the matrix to change of overall step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87cd311",
   "metadata": {},
   "source": [
    "First, let's acces at the total time of the associated overall step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4d9399",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_time = np.asarray(M_reso.loc[[(-1,\"(null)\",\"Temps total\")],[\"time_(s)\"]])[0][0]\n",
    "print(\"Total time of the resolution =\",total_time, \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546ab1c9",
   "metadata": {},
   "source": [
    "The number of time steps is simply the count of the counter \"Resoudre (timestep loop)\". One can acces it by using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e8b453",
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps=np.asarray(M_reso.loc[[(-1,\"(null)\",\"Resoudre (timestep loop)\")],[\"count\"]])[0][0]\n",
    "print('Number of time steps =', timesteps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b367272",
   "metadata": {},
   "source": [
    "Under some conditions, such as a strictly positive number of time steps, most of the aggregated quantities of the CASE_NAME.TU file can be retrieved as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdf6eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "solveur_Axb = np.asarray(M_reso.loc[[(-1,\"(null)\",\"SolveurSys::resoudre_systeme\")],[\"t_max\"]])[0][0]/timesteps\n",
    "print('Maximum time taken by the solver of Ax =b per time step',solveur_Axb, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443f7686",
   "metadata": {},
   "outputs": [],
   "source": [
    "solveur_diffusion_implicite = np.asarray(M_reso.loc[[(-1,\"(null)\",\"Equation_base::Gradient_conjugue_diff_impl\")],[\"t_max\"]])[0][0]/timesteps\n",
    "print('Maximum time taken for solving the diffusion part per time step = ',solveur_diffusion_implicite ,\"s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147be758",
   "metadata": {},
   "outputs": [],
   "source": [
    "assemblage_matrice_implicite = np.asarray(M_reso.loc[[(-1,\"(null)\",\"Assembleur::assembler\")],[\"t_max\"]])[0][0]/timesteps\n",
    "print('Maximum time taken for creating the matrix per time step, when using implicit solver = ',assemblage_matrice_implicite,\"s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8282a853",
   "metadata": {},
   "outputs": [],
   "source": [
    "mettre_a_jour = np.asarray(M_reso.loc[[(-1,\"(null)\",\"::mettre_a_jour\")],[\"t_max\"]])[0][0]/timesteps\n",
    "print('Maximum time taken for updating the matrix per time step = ', mettre_a_jour, \"s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277a1d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_vars = np.asarray(M_reso.loc[[(-1,\"(null)\",\"Schema_Implicite_4eqs::update_vars\")],[\"t_max\"]])[0][0]/timesteps\n",
    "print(update_vars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5bc155",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_fields = np.asarray(M_reso.loc[[(-1,\"(null)\",\"Probleme_Diphasique_base::updateGivenFields\")],[\"t_max\"]])[0][0]/timesteps\n",
    "print(update_fields)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdac3669",
   "metadata": {},
   "outputs": [],
   "source": [
    "operateurs_convection = np.asarray(M_reso.loc[[(-1,\"(null)\",\"Operateur_Conv::ajouter/calculer\")],[\"t_max\"]])[0][0]/timesteps\n",
    "print('Maximum time per time step for computing the operator of convection =',operateurs_convection,'s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb0c659",
   "metadata": {},
   "outputs": [],
   "source": [
    "operateurs_diffusion =  np.asarray(M_reso.loc[[(-1,\"(null)\",\"Operateur_Diff::ajouter/calculer\")],[\"t_max\"]])[0][0]/timesteps\n",
    "print('Maximum time per time step for computing the operator of convection =',operateurs_diffusion,'s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dde8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "operateurs_decroissance =  np.asarray(M_reso.loc[[(-1,\"(null)\",\"Operateur_Decr::ajouter/calculer\")],[\"t_max\"]])[0][0]/timesteps\n",
    "print('Maximum time per time step for computing the operator decreasing =',operateurs_decroissance,'s')          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80354c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "operateurs_gradient = np.asarray(M_reso.loc[[(-1,\"(null)\",\"Operateur_Grad::ajouter/calculer\")],[\"t_max\"]])[0][0]/timesteps\n",
    "print('Maximum time per time step for computing the gradient =',operateurs_gradient,'s')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb78ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "operateurs_divergence =  np.asarray(M_reso.loc[[(-1,\"(null)\",\"Operateur_Div::ajouter/calculer\")],[\"t_max\"]])[0][0]/timesteps\n",
    "print('Maximum time per time step for computing the operator divergence =',operateurs_divergence,'s')         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa6e18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "operateurs_source = np.asarray(M_reso.loc[[(-1,\"(null)\",\"Source::ajouter/calculer\")],[\"t_max\"]])[0][0]/timesteps\n",
    "print('Maximum time per time step for computing source terms =',operateurs_source,'s')          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0946d445",
   "metadata": {},
   "outputs": [],
   "source": [
    "operations_post_traitement =  np.asarray(M_reso.loc[[(-1,\"(null)\",\"Pb_base::postraiter\")],[\"t_max\"]])[0][0]/timesteps\n",
    "print('Maximum time per time step for post treatment operations =',operations_post_traitement,'s')          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8698b093",
   "metadata": {},
   "outputs": [],
   "source": [
    "calcul_dt = np.asarray(M_reso.loc[[(-1,\"(null)\",\"Operateur::calculer_pas_de_temps\")],[\"t_max\"]])[0][0]/timesteps\n",
    "print('Maximum time per time step for computing the time step =',calcul_dt,'s')          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4513237e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modele_turbulence = np.asarray(M_reso.loc[[(-1,\"(null)\",\"ModeleTurbulence*::mettre_a_jour\")],[\"t_max\"]])[0][0]/timesteps\n",
    "print('Maximum time per time step for trating the turbulence =',modele_turbulence,'s')          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c64010",
   "metadata": {},
   "outputs": [],
   "source": [
    "operations_sauvegarde = np.asarray(M_reso.loc[[(-1,\"(null)\",\"Probleme_base::sauver\")],[\"t_max\"]])[0][0]/timesteps\n",
    "print('Maximum time per time step for printing back-up =',operations_sauvegarde,'s')          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f523eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "marqueur1 = np.asarray(M_reso.loc[[(-1,\"(null)\",\"m1\")],[\"t_max\"]])[0][0]/timesteps        \n",
    "print('Maximum time per time step for doing the operation tracked by m1 =',marqueur1,'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363f0f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "marqueur2 = np.asarray(M_reso.loc[[(-1,\"(null)\",\"m2\")],[\"t_max\"]])[0][0]/timesteps\n",
    "print('Maximum time per time step for doing the operation tracked by m2 =',marqueur2,'s')          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2646307",
   "metadata": {},
   "outputs": [],
   "source": [
    "marqueur3 = np.asarray(M_reso.loc[[(-1,\"(null)\",\"m3\")],[\"t_max\"]])[0][0]/timesteps\n",
    "print('Maximum time per time step for doing the operation tracked by m3 =',marqueur3,'s')          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b499b333",
   "metadata": {},
   "outputs": [],
   "source": [
    "calcul_divers = np.asarray(M_reso.loc[[(-1,\"(null)\",\"Divers\")],[\"t_max\"]])[0][0]/timesteps\n",
    "print('Maximum time per time step for doing operations tracked by calcul_divers =',calcul_divers,'s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc36d7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nb_echange_espace_virtuel_per_ts = np.asarray(M_reso.loc[[(-1,\"(null)\",\"DoubleVect/IntVect::echange_espace_virtuel\")],[\"c_max\"]])[0][0]/timesteps\n",
    "print(\"Maximum of bytes exchanged per time steps between partition's domains\",Nb_echange_espace_virtuel_per_ts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312ffd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nb_MPI_allreduce_per_ts = np.asarray(M_reso.loc[[(-1,\"MPI_allreduce\",\"Aggregated over family\")],[\"c_max\"]])[0][0]/timesteps\n",
    "print('Maximum of MPI_allreduce per time step',Nb_MPI_allreduce_per_ts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52965c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nb_solveur_per_ts = np.asarray(M_reso.loc[[(-1,\"(null)\",\"SolveurSys::resoudre_systeme\")],[\"c_max\"]])[0][0]/timesteps\n",
    "print('Maximum number of solver called per time step =',Nb_solveur_per_ts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d4c731",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (np.asarray(M_reso.loc[[(-1,\"(null)\",\"SolveurSys::resoudre_systeme\")],[\"c_max\"]])[0][0] > 0 ):\n",
    "    Secondes_per_solveur = np.asarray(M_reso.loc[[(-1,\"(null)\",\"SolveurSys::resoudre_systeme\")],[\"t_max\"]])[0][0] / np.asarray(M_reso.loc[[(-1,\"(null)\",\"SolveurSys::resoudre_systeme\")],[\"c_max\"]])[0][0]\n",
    "    Iterations_per_solveur = np.asarray(M_reso.loc[[(-1,\"(null)\",\"SolveurSys::resoudre_systeme\")],[\"q_max\"]])[0][0]/np.asarray(M_reso.loc[[(-1,\"(null)\",\"SolveurSys::resoudre_systeme\")],[\"c_max\"]])[0][0]\n",
    "    print('Maximum time per step used for solving the inversion problem =',Secondes_per_solveur)\n",
    "    print('Maximum iteration number for solving the inversion problem = ',Iterations_per_solveur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2319ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (np.asarray(M_reso.loc[[(-1,\"(null)\",\"Probleme_base::sauver\")],[\"c_max\"]])[0][0]>0):\n",
    "    Nb_sauvegardes = np.asarray(M_reso.loc[[(-1,\"(null)\",\"Probleme_base::sauver\")],[\"c_max\"]])\n",
    "    Data_per_sauvegarde = (Nb_proc*np.asarray(M_reso.loc[[(-1,\"(null)\",\"Probleme_base::sauver\")],[\"Quantity\"]]))[0][0]/(np.asarray(M_reso.loc[[(-1,\"(null)\",\"Probleme_base::sauver\")],[\"c_max\"]])[0][0] * 1024 *1024)\n",
    "    print('Maximum number of back-up created :', Nb_sauvegardes)\n",
    "    print('Average bytes stored per back-up :', Data_per_sauvegarde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6938aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (np.asarray(M_reso.loc[[(-1,\"GPU_copy\",\"GPU_copyToDevice\")],[\"c_max\"]])>0):\n",
    "    GPU_libraries = np.asarray(M_reso.loc[[(-1,\"GPU_library\",\"GPU_library\")],[\"c_max\"]])[0][0]/np.asarray(M_reso.loc[[(-1,\"GPU_library\",\"GPU_library\")],[\"t_max\"]])[0][0]/1024/1024/1024\n",
    "    GPU_kernel = np.asarray(M_reso.loc[[(-1,\"GPU_kernel\",\"GPU_kernel\")],[\"c_max\"]])[0][0]/np.asarray(M_reso.loc[[(-1,\"GPU_kernel\",\"GPU_kernel\")],[\"t_max\"]])[0][0]/1024/1024/1024\n",
    "    Copy_H2D = np.asarray(M_reso.loc[[(-1,\"GPU_copy\",\"GPU_copyToDevice\")],[\"c_max\"]])[0][0]\n",
    "    print(GPU_libraries)\n",
    "    print(GPU_kernel)\n",
    "    print(Copy_H2D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61c9ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (np.asarray(M_reso.loc[[(-1,\"IO\",\"write\")],[\"time_(s)\"]]) >0):\n",
    "    Debit_write_seq = Nb_proc*np.asarray(M_reso.loc[[(-1,\"IO\",\"write\")],[\"Quantity\"]])[0][0]/np.asarray(M_reso.loc[[(-1,\"IO\",\"write\")],[\"t_max\"]])[0][0]/1024/1024\n",
    "    print('Sequential writing output :',Debit_write_seq, 'Mo/s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f01786",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (np.asarray(M_reso.loc[[(-1,\"IO\",\"MPI_File_write_all\")],[\"time_(s)\"]])[0][0] >0):\n",
    "    Debit_write_par = Nb_proc*np.asarray(M_reso.loc[[(-1,\"IO\",\"MPI_File_write_all\")],[\"Quantity\"]])/np.asarray(M_reso.loc[[(-1,\"IO\",\"MPI_File_write_all\")],[\"time_(s)\"]])/1024/1024\n",
    "    print('Parallel writing output :',Debit_write_par, 'Mo/s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ec1dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (np.asarray(M_reso.loc[[(-1,\"MPI_sendrecv\",\"Aggregated over family\")],[\"c_max\"]])> 0):\n",
    "    Communications_avg = 0.1 * math.floor(1000* ( np.asarray(M_reso.loc[[(-1,\"MPI_sendrecv\",\"Aggregated over family\")],[\"time_(s)\"]])[0][0] + np.asarray(M_reso.loc[[(-1,\"MPI_allreduce\",\"Aggregated over family\")],[\"time_(s)\"]])[0][0] )/ (total_time + 0.001) )\n",
    "    Communications_max = 0.1 * math.floor(1000* ( np.asarray(M_reso.loc[[(-1,\"MPI_sendrecv\",\"Aggregated over family\")],[\"t_max\"]])[0][0] + np.asarray(M_reso.loc[[(-1,\"MPI_allreduce\",\"Aggregated over family\")],[\"t_max\"]])[0][0] )/ (total_time + 0.001) )\n",
    "    Communications_min = 0.1 * math.floor(1000* ( np.asarray(M_reso.loc[[(-1,\"MPI_sendrecv\",\"Aggregated over family\")],[\"t_min\"]])[0][0] + np.asarray(M_reso.loc[[(-1,\"MPI_allreduce\",\"Aggregated over family\")],[\"t_min\"]])[0][0] )/ (total_time + 0.001) )\n",
    "    print('Average percent of time of communications = ',Communications_avg)\n",
    "    print('Minimum percent of time of communications = ',Communications_min)\n",
    "    print('Maximum percent of time of communications = ',Communications_max)\n",
    "    if (np.asarray(M_reso.loc[[(-1,\"MPI_sendrecv\", \"MPI_send_recv\")],[\"time_(s)\"]]) > 0):\n",
    "        max_bandwidth = 1.0e-6 * np.asarray(M_reso.loc[[(-1,\"MPI_sendrecv\", \"MPI_send_recv\")],[\"q_max\"]])[0][0]/np.asarray(M_reso.loc[[(-1,\"MPI_sendrecv\", \"MPI_send_recv\")],[\"t_min\"]])[0][0]\n",
    "        print('Evaluation of the maximum badnwidth = ',max_bandwidth, ' MB/s')\n",
    "    Total_network_traffic = Nb_proc * 1.0e-6 * np.asarray(M_reso.loc[[(-1,\"MPI_sendrecv\",\"Aggregated over family\")],[\"Quantity\"]])[0][0] / timesteps\n",
    "    Average_message_size = np.asarray(M_reso.loc[[(-1,\"MPI_sendrecv\",\"Aggregated over family\")],[\"Quantity\"]])[0][0] / np.asarray(M_reso.loc[[(-1,\"MPI_sendrecv\",\"Aggregated over family\")],[\"count\"]])[0][0]\n",
    "    print('Average total size of send messages per time step = ',Total_network_traffic, ' B per time step')\n",
    "    print('Average size of send messages per exchange = ',Average_message_size, ' MB/s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f33bd6f",
   "metadata": {},
   "source": [
    "# Table of the counters in TRUST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c2a226",
   "metadata": {},
   "source": [
    "| Counter_Id_number | Counter_ID | Counter name | Counter family | Is comm | Quantity increment|\n",
    "|:--------:| :--------:|:--------:|:--------:|:--------:|:--------:|\n",
    "| 0 | temps_total_execution_counter_ | Temps total | Null | 0 | 0 |\n",
    "| 1 | initialisation_calcul_counter_ | Preparer calcul | Null | 0 | 0 |\n",
    "| 2 | timestep_counter_ | Resoudre (timestep loop) | Null | 0 | 0 |\n",
    "| 3 | solv_sys_counter_ | SolveurSys::resoudre_systeme | Null | 0 | 0 |\n",
    "| 4 | solv_sys_petsc_counter_ | Solveurpetsc::resoudre_systeme | Null | 0 | 1 |\n",
    "| 5 | diffusion_implicite_counter_ | Equation_base::Gradient_conjugue_diff_impl | Null | 0 | 0 |\n",
    "| 6 | dt_counter_ | Operateur::calculer_pas_de_temps | Null | 0 | 0 | \n",
    "| 7 | nut_counter_ | ModeleTurbulence*::mettre_a_jour | Null | 0 | 0| \n",
    "| 8 | convection_counter_ | Operateur_Conv::ajouter/calculer | Null | 0 | 0 |\n",
    "| 9 | diffusion_counter_ | Operateur_Diff::ajouter/calculer | Null | 0 | 0 |\n",
    "| 10 | decay_counter_ | Operateur_Decr::ajouter/calculer | Null | 0 | 0 |\n",
    "| 11 | gradient_counter_ | Operateur_Grad::ajouter/calculer | Null | 0 | 0 |\n",
    "| 12 | divergence_counter_ | Operateur_Div::ajouter/calculer | Null | 0 | 0 |\n",
    "| 13 | source_counter_ | Source::ajouter/calculer | Null | 0 | 0 |\n",
    "| 14 | postraitement_counter_ | Pb_base::postraiter | Null | 0 | 0 |\n",
    "| 15 | sauvegarde_counter_ | Probleme_base::sauver | Null | 0 | number of bytes saved when using the function int Probleme_base::sauvegarder(Sortie& os) |\n",
    "| 16 | temporary_counter_ | temporary | Null | 0 | 0 |\n",
    "| 17 | assemblage_sys_counter_ | Assembleur::assembler | Null | 0 | 0 |\n",
    "| 18 | update_vars_counter_ | Schema_Implicite_4eqs::update_vars | Null | 0 | 0 |\n",
    "| 19 | update_fields_counter_ | Probleme_Diphasique_base::updateGivenFields | Null | 0 | 0 |\n",
    "| 20 | mettre_a_jour_counter_ | ::mettre_a_jour | Null | 0 | 0\n",
    "| 21 | divers_counter_ | Divers | Null | 0 | 0 |\n",
    "| 22 | m1_counter_ | m1 | Null | 0 | 0 |\n",
    "| 23 | m2_counter_ | m2 | Null | 0 | 0 |\n",
    "| 24 | m3_counter_ | m3 | Null | 0 | 0 |\n",
    "| 25 | probleme_fluide_ | pb_fluide | Null | 0 | 0 |\n",
    "| 26 | probleme_combustible_ | pb_combustible | Null | 0 | 0 |\n",
    "| 27 | echange_vect_counter_ | DoubleVect/IntVect::echange_espace_virtuel | 0 | 1 | 0 |\n",
    "| 28 | mpi_sendrecv_counter_  | MPI_send_recv\" | \"MPI_sendrecv\" | 1 | size of the exchanged data in bytes | \n",
    "| 29 | mpi_send_counter_ | MPI_send | MPI_sendrecv | 1 | size of the exchanged data in bytes | \n",
    "| 30 | mpi_recv_counter_ | MPI_recv | MPI_sendrecv | 1 | size of the exchanged data in bytes |\n",
    "| 31 | mpi_bcast_counter_ | MPI_broadcast | MPI_sendrecv | 1 | size of the exchanged data in bytes |\n",
    "| 32 | mpi_alltoall_counter_ | MPI_alltoall | MPI_sendrecv | 1 size of the exchanged data in bytes |\n",
    "| 33 | mpi_allgather_counter_ | MPI_allgather | MPI_sendrecv | 1 | size of the exchanged data in bytes |\n",
    "| 34 | mpi_gather_counter_ | MPI_gather | MPI_sendrecv | 1 | size of the exchanged data in bytes |\n",
    "| 35 | mpi_partialsum_counter_ | MPI_partialsum | MPI_allreduce | 1 | 0 |\n",
    "| 36 | mpi_sumdouble_counter_ | MPI_sumdouble | MPI_allreduce | 1 | 0 |\n",
    "| 37 | mpi_mindouble_counter_ | MPI_mindouble | MPI_allreduce | 1 | 0 |\n",
    "| 38 | mpi_maxdouble_counter_ | MPI_maxdouble | MPI_allreduce | 1 | 0 |\n",
    "| 39 | mpi_sumfloat_counter_ | MPI_sumfloat | MPI_allreduce | 1 | 0 |\n",
    "| 40 | mpi_minfloat_counter_ | MPI_minfloat | MPI_allreduce | 1 | 0 |\n",
    "| 41 | mpi_maxfloat_counter_  | MPI_maxfloat | MPI_allreduce | 1 | 0 |\n",
    "| 42 | mpi_sumint_counter_ | MPI_sumint | MPI_allreduce | 1 | 0 |\n",
    "| 43 | mpi_minint_counter_ | MPI_minint | MPI_allreduce | 1 | 0 |\n",
    "| 44 | mpi_maxint_counter_ | MPI_maxint | MPI_allreduce | 1 | 0 |\n",
    "| 45 | mpi_barrier_counter_ | MPI_barrier | MPI_allreduce | 1 | 0 |\n",
    "| 46 | gpu_library_counter_  | GPU_library | GPU_library | 0 | 0 |\n",
    "| 47 | gpu_kernel_counter_  | GPU_kernel | GPU_kernel | 0 | 0 |\n",
    "| 48 | gpu_copytodevice_counter_ | GPU_copyToDevice | GPU_copy | 0 | Size of the exchanged data |\n",
    "| 49 | gpu_copyfromdevice_counter_ | GPU_copyFromDevice | GPU_copy | 0 | 0 if called in Solv_Petsc::Update_solution(DoubleVect& solution) , number of rows of the local TRUST Matrix if used in Solv_rocALUTION::resoudre_systeme(const Matrice_Base& a, const DoubleVect& b, DoubleVect& x) |\n",
    "| 50 | IO_EcrireFicPartageMPIIO_counter_ | MPI_File_write_all | IO | 0 | size of written data | \n",
    "| 51 | IO_EcrireFicPartageBin_counter_ | write | IO | 0 | buffer size of the accumulated data on each processor when using syncfile()|\n",
    "| 52 | interprete_scatter_counter_ | Scatter | Null | 0 | 0 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a12edf4",
   "metadata": {},
   "source": [
    "Moreover, two counters have custom count increment :\n",
    "\n",
    "| Counter_Id_number | Counter_ID | Counter name | count custom increment|\n",
    "|:--------:| :--------:|:--------:|:--------:|\n",
    "| 28 | mpi_sendrecv_counter_  | MPI_send_recv\" | mpi_nrequests_ |\n",
    "| 47 | gpu_kernel_counter_  | GPU_kernel | number of exchange | \n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
